# Week 4: Ensemble Methods

## Focus: Random Forest, Gradient Boosting, AdaBoost

---

## Theory (3 hours)

### Theoretical Topics

- Ensemble learning concepts
- Bagging vs Boosting
- How Random Forest works
- Gradient Boosting algorithm
- AdaBoost algorithm

---

## Practice (4 hours)

### Practical Topics

- Random Forest Classifier
- Gradient Boosting Classifier (GBM)
- AdaBoost Classifier
- XGBoost basics
- Feature importance analysis

### Code Practice

```python
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
import xgboost as xgb
```

---

## Project (2 hours)

### Credit Card Fraud Detection

Build an ensemble model for fraud detection.

**Challenge:** Achieve 95%+ accuracy

**Steps:**

1. Load credit card fraud dataset
2. Handle highly imbalanced data
3. Train Random Forest model
4. Train Gradient Boosting model
5. Compare and ensemble models
6. Optimize for fraud detection

---

## Resources

- XGBoost documentation
- Kaggle fraud detection datasets

---

## Checklist

- [ ] Understand ensemble learning
- [ ] Implement Random Forest
- [ ] Implement Gradient Boosting
- [ ] Implement AdaBoost
- [ ] Explore XGBoost
- [ ] Complete fraud detection project (95%+ accuracy)
